{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extract crawled_data/matches to new_lake/50k_matches.parquet and create check_download_player_id.parquet\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from progress.bar import IncrementalBar\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import sys\n",
    "import requests\n",
    "\n",
    "\n",
    "ROOT = f'D:\\Python\\hackathon'\n",
    "BASE_PATH = f'D:\\Python\\hackathon\\source'\n",
    "SUB_FOLDER = \"crawled_data/matches\"\n",
    "OUTPUT_FILE = \"new_lake/50k_matches.parquet\"\n",
    "CHECK_FILE = \"check_download_player_id.parquet\"\n",
    "# add my source\n",
    "SOUCRE_PATH = str(Path(ROOT, \"source\"))\n",
    "sys.path.append(SOUCRE_PATH)\n",
    "from common import *\n",
    "\n",
    "columns = [\n",
    "    \"match_id\",\n",
    "    \"game_mode\",\n",
    "    \"account_id01\",\n",
    "    \"hero_id01\",\n",
    "    \"isRadiant01\",\n",
    "    \"account_id02\",\n",
    "    \"hero_id02\",\n",
    "    \"isRadiant02\",\n",
    "    \"account_id03\",\n",
    "    \"hero_id03\",\n",
    "    \"isRadiant03\",\n",
    "    \"account_id04\",\n",
    "    \"hero_id04\",\n",
    "    \"isRadiant04\",\n",
    "    \"account_id05\",\n",
    "    \"hero_id05\",\n",
    "    \"isRadiant05\",\n",
    "    \"account_id06\",\n",
    "    \"hero_id06\",\n",
    "    \"isRadiant06\",\n",
    "    \"account_id07\",\n",
    "    \"hero_id07\",\n",
    "    \"isRadiant07\",\n",
    "    \"account_id08\",\n",
    "    \"hero_id08\",\n",
    "    \"isRadiant08\",\n",
    "    \"account_id09\",\n",
    "    \"hero_id09\",\n",
    "    \"isRadiant09\",\n",
    "    \"account_id10\",\n",
    "    \"hero_id10\",\n",
    "    \"isRadiant10\",\n",
    "    \"radiant_win\",\n",
    "    \"leagueid\",\n",
    "    \"region\",\n",
    "    \"patch\",\n",
    "]\n",
    "matches_path = str(Path(ROOT, SUB_FOLDER))\n",
    "# print(matches_path)\n",
    "\n",
    "match_list = glob.glob(f\"{matches_path}\\*\\*\\*\\*.json\")\n",
    "# for (dir_path, dir_names, file_names) in os.walk(matches_path):\n",
    "#     match_list.extend(file_names)\n",
    "# print(len(match_list))\n",
    "\n",
    "bar = IncrementalBar(\n",
    "    \"Extracting matches and players id...\",\n",
    "    max=len(match_list),\n",
    "    suffix=\"%(index)d/%(max)d | %(elapsed_td)s\",\n",
    ")\n",
    "\n",
    "# matches_id = [get_match_id(file) for file in match_list]\n",
    "# print(len(match_id))\n",
    "bu = 0\n",
    "data = {}\n",
    "for col in columns:\n",
    "    data[col] = []\n",
    "account_list = []\n",
    "now = datetime.now()\n",
    "crawl_time = int(np.rint(datetime.timestamp(now)))\n",
    "error_files = []\n",
    "for file in match_list:\n",
    "    # print(file)\n",
    "    # print(type(file))\n",
    "    with open(file, \"rb\") as f:\n",
    "        try:\n",
    "            data_json = json.load(f)\n",
    "            # ignore the match if this match dont have players.\n",
    "            if \"players\" in data_json.keys():\n",
    "                players_data = data_json[\"players\"]\n",
    "                for i in range(10):\n",
    "                    num = str(i + 1).zfill(2)\n",
    "                    if i < len(players_data):\n",
    "                        data[\"account_id\" + num].append(players_data[i][\"account_id\"])\n",
    "                        data[\"hero_id\" + num].append(players_data[i][\"hero_id\"])\n",
    "                        data[\"isRadiant\" + num].append(players_data[i][\"isRadiant\"])\n",
    "                        account_list.append(\n",
    "                            players_data[i][\"account_id\"]\n",
    "                        )  # get player id to save\n",
    "                    else:\n",
    "                        data[\"account_id\" + num].append(None)\n",
    "                        data[\"hero_id\" + num].append(None)\n",
    "                        data[\"isRadiant\" + num].append(None)\n",
    "                for col in [\n",
    "                    \"match_id\",\n",
    "                    \"game_mode\",\n",
    "                    \"radiant_win\",\n",
    "                    \"leagueid\",\n",
    "                    \"region\",\n",
    "                    \"patch\",\n",
    "                ]:\n",
    "                    if col in data_json.keys():\n",
    "                        data[col].append(data_json[col])\n",
    "                    else:\n",
    "                        data[col].append(None)\n",
    "            else:\n",
    "                bar.next()\n",
    "                error_files.append(file)\n",
    "                continue\n",
    "            bar.next()\n",
    "        except:\n",
    "            error_files.append(file)\n",
    "            bar.next()\n",
    "            continue\n",
    "bar.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "account_list1 = set(account_list)\n",
    "account_list1.discard(None)\n",
    "accounts = [*account_list1]\n",
    "# print(len(accounts))\n",
    "account_df = pd.DataFrame(accounts, columns=[\"player_id\"])\n",
    "account_df[\"time\"] = crawl_time\n",
    "account_df[\"downloaded\"] = 0\n",
    "# print(\"Error files:\", error_files)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3746\n"
     ]
    }
   ],
   "source": [
    "print(len(error_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6612710428', '6612710693', '6612711274', '6612711903', '6612712350', '6612713043', '6612714518', '6612718279', '6612718366', '6612720288']\n",
      "   match_id  start_time  downloaded\n",
      "0     12158  1314201270           0\n",
      "1     12164  1314205112           0\n",
      "2     12172  1314210111           0\n",
      "3     12185  1314213494           0\n",
      "4     12198  1314218033           0\n"
     ]
    }
   ],
   "source": [
    "# reset check downloaded of error_files= 0\n",
    "if error_files != []:\n",
    "    bar1 = IncrementalBar(\n",
    "        \"Reseting check downloaded...\",\n",
    "        max=len(error_files),\n",
    "        suffix=\"%(index)d/%(max)d | %(elapsed_td)s\",\n",
    "    )\n",
    "    errors_id = [get_filename_extension(err)[0] for err in error_files]\n",
    "    print(errors_id[:10])\n",
    "    out_put = str(Path(ROOT, \"check_download_match_id.parquet\"))\n",
    "    check_download_df = pd.read_parquet(out_put)\n",
    "    for match_id in errors_id:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_download_df.loc[check_download_df[\"match_id\"] == match_id, \"downloaded\" ] = 0\n",
    "        bar1.next()\n",
    "    check_download_df.to_parquet(out_put, index=False)\n",
    "    bar1.finish()\n",
    "    # temp_df = pd.read_parquet(file_path)\n",
    "    # # print(df.head())\n",
    "    # check_download_df.loc[check_download_df[\"match_id\"] == id, \"downloaded\"] = value\n",
    "    print(check_download_df.head())\n",
    "    # temp_df.to_parquet(file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11791492</th>\n",
       "      <td>6612710428</td>\n",
       "      <td>1654957026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            match_id  start_time  downloaded\n",
       "11791492  6612710428  1654957026           0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ms = 6612710428\n",
    "check_download_df[check_download_df[\"match_id\"] == 6612710428]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_download_df.loc[check_download_df[\"match_id\"] == ms, \"downloaded\" ] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11791492</th>\n",
       "      <td>6612710428</td>\n",
       "      <td>1654957026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            match_id  start_time  downloaded\n",
       "11791492  6612710428  1654957026           1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_download_df[check_download_df[\"match_id\"] == 6612710428]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in data.keys():\n",
    "#     print(str(k), len(data[k]))\n",
    "match_df = pd.DataFrame(data)\n",
    "# print(df.head())\n",
    "account_df.to_parquet(CHECK_FILE, index=False)\n",
    "match_df.to_parquet(OUTPUT_FILE, index=False)\n",
    "print(\"Done.\")\n",
    "\n",
    "# df = pd.DataFrame(data_json)\n",
    "# print(data)\n",
    "\n",
    "# df = pd.read_json(\"crawled_data/matches/2022/7/10/6654586166.json\")\n",
    "# print(df.head())\n",
    "if __name__ == \"__main__\":\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3328\n",
      "   solo_competitive_rank  leaderboard_rank  competitive_rank  \\\n",
      "0                    NaN               NaN               NaN   \n",
      "1                    NaN               NaN               NaN   \n",
      "2                    NaN            4712.0               NaN   \n",
      "3                    NaN               NaN               NaN   \n",
      "4                 1161.0               NaN               NaN   \n",
      "5                 3421.0               NaN               NaN   \n",
      "6                 5954.0            5002.0            4922.0   \n",
      "7                    NaN               NaN               NaN   \n",
      "8                    NaN               NaN               NaN   \n",
      "9                    NaN               NaN               NaN   \n",
      "\n",
      "         mmr_estimate                                            profile  \\\n",
      "0  {'estimate': 3850}  {'account_id': 100009801, 'personaname': 'kill...   \n",
      "1  {'estimate': 2932}  {'account_id': 1000479178, 'personaname': 'bag...   \n",
      "2  {'estimate': 4544}  {'account_id': 1000737033, 'personaname': 'Rev...   \n",
      "3  {'estimate': 3167}  {'account_id': 100141491, 'personaname': 'twit...   \n",
      "4  {'estimate': 2030}  {'account_id': 100144521, 'personaname': 'bura...   \n",
      "5  {'estimate': 3450}  {'account_id': 100145550, 'personaname': 'Pó d...   \n",
      "6  {'estimate': 5158}  {'account_id': 100277704, 'personaname': 'Reve...   \n",
      "7  {'estimate': 3620}  {'account_id': 1003225734, 'personaname': 'Nik...   \n",
      "8  {'estimate': 3597}  {'account_id': 100402771, 'personaname': 'Zozo...   \n",
      "9  {'estimate': 3207}  {'account_id': 100406278, 'personaname': 'Na4e...   \n",
      "\n",
      "   rank_tier  \n",
      "0       61.0  \n",
      "1       42.0  \n",
      "2       80.0  \n",
      "3       44.0  \n",
      "4       43.0  \n",
      "5       45.0  \n",
      "6       80.0  \n",
      "7       53.0  \n",
      "8       42.0  \n",
      "9       62.0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\100794739.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\103940576.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\1059062128.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\1059586224.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\109314489.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\1102053806.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\112853378.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\114950606.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\114950635.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\115736750.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\118625711.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\121242023.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\121766293.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\122552810.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\122683786.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\123994551.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\125305316.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\126091747.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\1273889200.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\1285292506.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\129761731.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\130548152.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\135135710.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\137101797.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\1372848580.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\139329977.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\145490193.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\151781871.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\154665325.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\155714025.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\157417878.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\160432574.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\160825794.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\162136466.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\163316155.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\164102553.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\165675449.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\166199568.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\168951929.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\169345445.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\171573651.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\185342898.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\188744095.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\190447997.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\199491758.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\209191282.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\220987514.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\224002169.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\226099663.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\228327543.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\23200234.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\251134123.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\259523044.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\317849786.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\321257834.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\321782187.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\332792212.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\340263366.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\34996623.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\358089183.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\367002043.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\368581553.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\384696722.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\389022189.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\402260417.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\409469394.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\414187950.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\418120077.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\418906518.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\419430800.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\464519586.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\48234616.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\69075062.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\71959019.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\75366894.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\78648751.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\81527053.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\85328252.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\857740724.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\858914996.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\89391555.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\900596203.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\98435532.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_info\\\\992746416.json']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "from progress.bar import IncrementalBar\n",
    "def player_info_etl_dataframe():\n",
    "    errors_list= []\n",
    "    data_dict ={'solo_competitive_rank':[],\t'leaderboard_rank':[], 'competitive_rank':[],'mmr_estimate':[],'profile':[],\t'rank_tier':[]}\n",
    "    columns = ['rank_tier','leaderboard_rank','profile','competitive_rank','mmr_estimate','solo_competitive_rank']\n",
    "    players_info_list = glob.glob(\"D:\\Python\\hackathon\\crawled_data\\players_info\\*.json\")\n",
    "    bar = IncrementalBar(\n",
    "        \"Extracting player...\",\n",
    "        max=len(players_info_list),\n",
    "        suffix=\"%(index)d/%(max)d | %(elapsed_td)s\",\n",
    "    )\n",
    "    print(len(players_info_list))\n",
    "    for player_info in players_info_list:\n",
    "        try:\n",
    "            with open(player_info,\"rb\") as f:\n",
    "                data = json.load(f)\n",
    "                data_dict['solo_competitive_rank'].append(data['solo_competitive_rank'])\n",
    "                data_dict['leaderboard_rank'].append(data['leaderboard_rank'])\n",
    "                data_dict['competitive_rank'].append(data['competitive_rank'])\n",
    "                data_dict['mmr_estimate'].append(data['mmr_estimate'])\n",
    "                data_dict['profile'].append(data['profile'])\n",
    "                data_dict['rank_tier'].append(data['rank_tier'])\n",
    "            \n",
    "        except Exception as e:\n",
    "            errors_list.append(player_info)\n",
    "        finally:\n",
    "            bar.next()\n",
    "    players_info_df =pd.DataFrame(data_dict)\n",
    "    return players_info_df,errors_list\n",
    "ka,err = player_info_etl_dataframe()\n",
    "print(ka.head(10))\n",
    "err\n",
    "# df[\"haha\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3327\n",
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\100794739.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\103940576.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\1059062128.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\1059586224.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\109314489.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\1102053806.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\111542540.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\112853378.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\114950606.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\114950635.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\115736750.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\118625711.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\121242023.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\121766293.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\122552810.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\122683786.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\123994551.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\125305316.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\126091747.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\1273889200.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\1285292506.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\129761731.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\130548152.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\135135710.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\137101797.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\1372848580.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\139329977.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\151781871.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\154665325.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\155714025.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\157417878.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\160432574.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\160825794.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\162136466.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\163316155.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\164102553.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\165675449.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\166199568.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\168951929.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\169345445.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\171573651.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\188744095.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\190447997.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\199491758.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\209191282.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\220987514.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\226099663.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\228327543.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\246022315.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\251134123.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\259523044.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\287179114.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\321257834.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\321782187.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\332792212.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\340263366.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\34996623.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\358089183.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\367002043.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\368581553.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\384696722.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\389022189.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\402260417.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\409469394.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\414187950.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\418120077.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\418906518.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\419430800.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\464519586.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\48234616.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\69075062.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\71959019.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\75366894.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\78648751.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\81527053.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\839392173.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\85328252.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\858914996.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\89391555.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\900596203.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\98435532.json',\n",
       " 'D:\\\\Python\\\\hackathon\\\\crawled_data\\\\players_wl\\\\992746416.json']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "from progress.bar import IncrementalBar\n",
    "\n",
    "def reset_download_error_files(check_file, errors_list:list, message=\"Reseting check downloaded of error files...\"):\n",
    "    if errors_list != []:\n",
    "        bar = IncrementalBar(\n",
    "           message,\n",
    "            max=len(error_files),\n",
    "            suffix=\"%(index)d/%(max)d | %(elapsed_td)s\",\n",
    "        )\n",
    "        errors_id = [int(get_filename_extension(err)[0]) for err in error_files]\n",
    "        # print(errors_id)\n",
    "        out_put = check_file\n",
    "        check_download_df = pd.read_parquet(out_put)\n",
    "        for match_id in errors_id:\n",
    "            check_download_df.loc[\n",
    "                check_download_df[\"match_id\"] == match_id, \"downloaded\"\n",
    "            ] = 0\n",
    "            bar.next()\n",
    "        check_download_df.to_parquet(out_put, index=False)\n",
    "        bar.finish()\n",
    "    pass\n",
    "\n",
    "\n",
    "def json_to_dataframe(input_path, columns ,message,check_file):\n",
    "    \"\"\"Return a pandas dataframe and list of error file path.\"\"\"\n",
    "    error_files= []\n",
    "    # data_dict ={\"win\":[],\"lose\":[]}\n",
    "    columns = [\"win\",\"lose\"]\n",
    "    data_dict = {col:[] for col in columns}\n",
    "\n",
    "    # players_info_list = glob.glob(\"D:\\Python\\hackathon\\crawled_data\\players_wl\\*.json\")\n",
    "    players_info_list = glob.glob(input_path)\n",
    "    bar = IncrementalBar(message,\n",
    "        max=len(players_info_list),\n",
    "        suffix=\"%(index)d/%(max)d | %(elapsed_td)s\",\n",
    "    )\n",
    "    print(len(players_info_list))\n",
    "    for player_info in players_info_list:\n",
    "        try:\n",
    "            with open(player_info,\"rb\") as f:\n",
    "                data = json.load(f)\n",
    "                for col in columns:\n",
    "                    data_dict[col].append(data[col])            \n",
    "        except Exception as e:\n",
    "            error_files.append(player_info)\n",
    "        finally:\n",
    "            bar.next()\n",
    "    df =pd.DataFrame(data_dict)\n",
    "    if errors_list == []:\n",
    "        return True, df\n",
    "    else:\n",
    "        return False, error_files\n",
    "columns = [\"win\",\"lose\"]\n",
    "ka,err = json_to_dataframe(\"D:\\Python\\hackathon\\crawled_data\\players_wl\\*.json\",columns,\"Extracting players info...\")\n",
    "print(ka)\n",
    "err\n",
    "\n",
    "# data_dict = {col:[] for col in columns}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47a5897a0978ead4aea8e205f081172506d14dd5b7431a8174922e247ec6cb98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
